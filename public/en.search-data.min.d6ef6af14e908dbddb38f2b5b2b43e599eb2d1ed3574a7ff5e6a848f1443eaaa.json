[{"id":0,"href":"/docs/track1/getting-started/","title":"Getting Started with Track 1","section":"Track 1","content":"Overview# For Track 1, we\u0026rsquo;ve allocated 2 shared vLLM instances to be used for your solutions in the challenge. These instances are OpenAI API compatible, meaning they can be interacted with tooling and libraries originally created for working with OpenAI.\nThe first instance can be located at eidf219-main.vms.os.eidf.epcc.ed.ac.uk:8000 and is a Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8 model under the hood, to be used for general purpose queries and code generation. The second instance is a visual reasoning focused model and can be found at eidf219-main.vms.os.eidf.epcc.ed.ac.uk:8001 (a Qwen/Qwen2.5-VL-32B-Instruct model under the hood).\nStep 1: Connecting to the API# Connecting from your team\u0026rsquo;s VM# The first and easiest way to connect to the API is to connect to your team\u0026rsquo;s VM by following the instructions found here. From there, you can run a test query against the vLLM instances like so:\ncurl http://eidf219-main.vms.os.eidf.epcc.ed.ac.uk:8000/v1/chat/completions -H \u0026#34;Content-Type: application/json\u0026#34; -d \u0026#39;{ \u0026#34;model\u0026#34;: \u0026#34;Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8\u0026#34;, \u0026#34;messages\u0026#34;: [ {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Give me a short introduction to large language models.\u0026#34;} ], \u0026#34;temperature\u0026#34;: 0.6, \u0026#34;top_p\u0026#34;: 0.95, \u0026#34;top_k\u0026#34;: 20, \u0026#34;max_tokens\u0026#34;: 32768 }\u0026#39;Connecting from your local machine with SSH tunelling# To connect to the vLLM instances from your local machine, you can use SSH tunneling. In a standard bash shell, the command looks like so,\nssh -J \u0026lt;your_username\u0026gt;@eidf-gateway.epcc.ed.ac.uk -L 8000:10.1.0.155:8000 -N \u0026lt;your_username\u0026gt;@\u0026lt;vm_ip\u0026gt;where \u0026lt;your_username\u0026gt; is replaced with the username given for your team\u0026rsquo;s VM, and \u0026lt;vm_ip\u0026gt; is the EIDF IP address associated with your team\u0026rsquo;s VM. Note: when connecting to the visual reasoning vLLM instance (the one using a Qwen/Qwen2.5-VL-32B-Instruct mode), replace 8000:10.1.0.155:8000 with 8001:10.1.0.155:8001.\nOnce you\u0026rsquo;ve done this, in a new window you should be able to run a similar test, now by querying the API as localhost:8000 (or localhost:8001 if you\u0026rsquo;re querying the visual reasoning instance).\ncurl http://localhost:8000/v1/chat/completions -H \u0026#34;Content-Type: application/json\u0026#34; -d \u0026#39;{ \u0026#34;model\u0026#34;: \u0026#34;Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8\u0026#34;, \u0026#34;messages\u0026#34;: [ {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Give me a short introduction to large language models.\u0026#34;} ], \u0026#34;temperature\u0026#34;: 0.6, \u0026#34;top_p\u0026#34;: 0.95, \u0026#34;top_k\u0026#34;: 20, \u0026#34;max_tokens\u0026#34;: 32768 }\u0026#39;Step 2: Programmatically interacting with the API# In Python, the openai package can be used to interact with the vLLM instance. Under the hood, this is largely a wrapper around the OpenAI REST API, so the insights from the previous sections still apply. I\u0026rsquo;ve included a few code samples to get you started with these below.\nTo query the Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8 model using the openai package:\nfrom openai import OpenAI openai_api_key = \u0026#34;EMPTY\u0026#34; # This can be left alone # Uncomment depending on where you\u0026#39;re running this script: # openai_api_base = \u0026#34;http://localhost:8000/v1\u0026#34; # I\u0026#39;m running from my local machine with SSH tunneling # openai_api_base = \u0026#34;http://eidf219-main.vms.os.eidf.epcc.ed.ac.uk:8000/v1\u0026#34; # I\u0026#39;m running from my team\u0026#39;s VM client = OpenAI( api_key=openai_api_key, base_url=openai_api_base, ) chat_response = client.chat.completions.create( model=\u0026#34;Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8\u0026#34;, messages=[ {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Give me a short introduction to large language models.\u0026#34;}, ], max_tokens=32768, temperature=0.6, top_p=0.95, extra_body={ \u0026#34;top_k\u0026#34;: 20, }, ) print(\u0026#34;Chat response:\u0026#34;, chat_response)To query the Qwen/Qwen2.5-VL-32B-Instruct model using REST API requests:\nimport requests import base64 # Uncomment depending on where you\u0026#39;re running this script: # openai_api_base = \u0026#34;http://localhost:8001/v1\u0026#34; # I\u0026#39;m running from my local machine with SSH tunneling # openai_api_base = \u0026#34;http://eidf219-main.vms.os.eidf.epcc.ed.ac.uk:8001/v1\u0026#34; # I\u0026#39;m running from my team\u0026#39;s VM # Replace this with your actual image URL image_url = \u0026#34;https://dashscope.oss-cn-beijing.aliyuncs.com/images/dog_and_girl.jpeg\u0026#34; # Download the image and encode it as base64 image_data = requests.get(image_url).content image_base64 = base64.b64encode(image_data).decode(\u0026#39;utf-8\u0026#39;) # Prepare the payload for the OpenAI-compatible API payload = { \u0026#34;model\u0026#34;: \u0026#34;Qwen/Qwen2.5-VL-32B-Instruct\u0026#34;, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;image_url\u0026#34;, \u0026#34;image_url\u0026#34;: {\u0026#34;url\u0026#34;: f\u0026#34;data:image/jpeg;base64,{image_base64}\u0026#34;}}, {\u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;What is inside this image?\u0026#34;} ] } ] } # Send the request to the local server response = requests.post(f\u0026#34;{openai_api_base}/chat/completions\u0026#34;, json=payload) # Print the model\u0026#39;s response print(response.json())"},{"id":1,"href":"/docs/track2/getting-started/","title":"Getting Started with Track 2","section":"Track 2","content":"Overview# This document will include challenge specific information and is useful to read even if you have prior experience with Kubernetes.\nTrack 2 teams will be given access to a shared kubernetes compute cluster. This cluster makes available 6 nodes, 4 of which with 8 x H200 GPUs, and 2 of which with 8 x H100 GPUs. The cluster is to be used for training and tuning your models.\nNote that the cluster can only be interacted with through your team\u0026rsquo;s VM. So, all commands given should be run on your team\u0026rsquo;s VM.\nCrash Course Kubernetes# In Kubernetes, state is expressed in the form of resources. Some common resource types are pods (like containers in docker), deployments (similar to a docker-compose file), and jobs.\nYou can perform actions on resources using the kubectl utility. For instance,\n# To list pods running: kubectl get pods # To create a resource from a file: kubectl -n eidf219ns create -f myjob.yaml # To see the logs emitted from a pod (pods are spawned by jobs) kubectl -n eidf219ns logs \u0026lt;pod_name\u0026gt; # To delete a broken or finished job: kubectl -n eidf219ns delete job \u0026lt;job_name\u0026gt;For this challenge, Job resources are the most relevent.\nRunning your first job# Jobs can be specified with yaml files. This makes them reproducible and much easier to debug. To actually create a resource specified by a yaml file, you can use the command kubectl -n eidf219ns create -f /path/to/file.yaml.\nAs an example:\napiVersion: batch/v1 kind: Job metadata: generateName: jobtest- labels: kueue.x-k8s.io/queue-name: eidf219ns-user-queue spec: completions: 1 backoffLimit: 1 ttlSecondsAfterFinished: 1800 template: metadata: name: job-test spec: containers: - name: cudasample image: nvcr.io/nvidia/k8s/cuda-sample:nbody-cuda11.7.1 args: [\u0026#34;-benchmark\u0026#34;, \u0026#34;-numbodies=512000\u0026#34;, \u0026#34;-fp64\u0026#34;, \u0026#34;-fullscreen\u0026#34;] resources: requests: cpu: 2 memory: \u0026#39;1Gi\u0026#39; limits: cpu: 2 memory: \u0026#39;4Gi\u0026#39; nvidia.com/gpu: 1 restartPolicy: NeverClaiming GPUs# The following will attempt to claim a GPU and then display PCIE devices in the logs.\napiVersion: batch/v1 kind: Job metadata: generateName: gpu-test-1- labels: kueue.x-k8s.io/queue-name: eidf219ns-user-queue app: gputest1 spec: # Selecter would go here template: metadata: labels: app: gputest1 spec: restartPolicy: Never containers: - name: ubuntu image: ubuntu:20.04 command: [\u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;apt-get update \u0026amp;\u0026amp; apt-get install lshw -y \u0026amp;\u0026amp; lshw -C display\u0026#34;] resources: limits: nvidia.com/gpu: 1 cpu: 1 memory: \u0026#34;4Gi\u0026#34;By default, it will pick a GPU variant and attempt to select specifically nodes with that GPU, so if you see that your Job is marked as pending for long periods, it may be worth trying to select other types of GPUs. This can be done adding the following lines where it says \u0026ldquo;Selecter would go here\u0026rdquo; in the code sample above:\nnodeSelector: nvidia.com/gpu-product: \u0026#39;\u0026lt;GPU Type\u0026gt;\u0026#39;See the EIDF Doc\u0026rsquo;s for more information.\nFAQ / Common Issues# Setting up my default namespace# If you\u0026rsquo;d like to avoid having to type -n eidf219ns every time, you can follow the instructions here to setup your default namespace.\nDoing so allows you to simply type kubectl get pods for instance to list all pods, rather than kubectl -n eidf219ns get pods\nPersistent Volume Claims# If you\u0026rsquo;d like a PVC created for your team, please message @emily.747 on Discord or email me.\nFurther Documentation# I\u0026rsquo;d highly recommend the following resources and documentation when you\u0026rsquo;re stuck:\nEIDF\u0026rsquo;s GPU Service Documentation Kubernetes Docs "},{"id":2,"href":"/docs/general/github_repo_setup/","title":"Setting up your GitHub Repo","section":"General","content":"How to make a private GitHub Repository on the Challenge Organisation# This guide assumes that you\u0026rsquo;ve been invited to the GitHub Organisation for the Challenge Week and that you\u0026rsquo;ve accepted this invite. If you\u0026rsquo;re unsure about this, please contact the Organisers in the Discord Server.\nStep 1: Go to the following link: https://github.com/compsoc-oe-week\nStep 2: Make a repository. You can do this by clicking the green \u0026lsquo;New\u0026rsquo; button next to the repository search.\nStep 3: Name your repository. This should be in the format \u0026lsquo;[track1/track2]_[teamName]\u0026rsquo;. For example, a team titled \u0026ldquo;Apples\u0026rdquo; on track 1 would name their repository \u0026rsquo;track1_apples\u0026rsquo;.\nStep 4: Under configuration, MAKE SURE that the repository visibility is SET TO PRIVATE.\nStep 5: Once done, you\u0026rsquo;re free to configure your repository in other ways. The key requirements are that the repo is private and follows the naming convention. Click \u0026lsquo;Create repository\u0026rsquo;\nStep 6: To add your team members, click on \u0026lsquo;Manage access\u0026rsquo;. Then click \u0026lsquo;Add people\u0026rsquo; and select the GitHub usernames of your teammates. Do not add anyone outside of your team to your private repository!\n"},{"id":3,"href":"/showcases/","title":"Showcases","section":"","content":" At the moment this page is empty# hi\n"},{"id":4,"href":"/docs/general/openeuler_container/","title":"START HERE - Getting started as a participant","section":"General","content":"Getting started as a participant# Create an SSH Key# For more info, click here or ask for help\nOn Linux/Mac# Run ssh-keygen Do not set a passphrase Save the key-pair somewhere you can find it On Windows# You can use PuTTY to create the key, likewise don\u0026rsquo;t set a passphrase See here for information Creating a SAFE account# Go to the SAFE website Fill out the necessary details You must use your student email Upload your SSH public key to the form - *.pub Press \u0026ldquo;Register\u0026rdquo; Check your email for confirmation, then finish registration by clicking the link and setting your password Joining the Hackathon Project# Go here to request to join the project Look for eidf219 - InfSoc GPU hackathon Select that, click Next then Apply We will approve your application as soon as we can We will then create you a login account for your VM You\u0026rsquo;ll get another email, set your password and MFA OTP You should already have Microsoft Authenticator for uni, but others will work Getting a VM created# We\u0026rsquo;ll aim to create VMs for teams before the day If you form a team on the day, we\u0026rsquo;ll need to create you a VM - so let us know! Connecting to your VM# You can connect to the VM CLI via a web interface (VDI), but we\u0026rsquo;d recommend using SSH in your terminal. To SSH to your VM you must first go through the EIDF gateway as a security measure, so your SSH command will likely take the form: ssh-add /path/to/ssh-key \u0026amp;\u0026amp; ssh -J [username]@eidf-gateway.epcc.ed.ac.uk [username]@[vm_ip] That is, your project account username The EIDF provides documentation on connecting via SSH - following this is best, if you\u0026rsquo;re struggling ask an organiser for help When prompted for your \u0026ldquo;OTP\u0026rdquo; enter the number from your MFA app. You should then see a shell inside your VM Spawning an openEuler container# You can follow these instructions on any Linux device, including the provided VM, or even your laptop. If you\u0026rsquo;re running Windows, we\u0026rsquo;d highly recommend checking out Windows Subsystem for Linux (WSL).\nPut the following into a file called Dockerfile: FROM openeuler/openeuler:latest SHELL [\u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;] RUN /usr/bin/dnf update -y RUN /usr/bin/dnf install -y python3 nodejs npm curl go sqlite htop RUN curl https://sh.rustup.rs -sSf | sh -s -- -y RUN . \u0026#34;$HOME/.cargo/env\u0026#34; RUN /usr/bin/dnf group install -y \u0026#34;Development Tools\u0026#34; WORKDIR /work ENTRYPOINT /bin/sh Put the following into a file called docker-compose.yaml: services: oe: build : . container_name: \u0026#34;oe\u0026#34; tty: true stdin_open: true volumes: - ./work:/work Connect your VM Start the container with docker compose build \u0026amp;\u0026amp; docker compose up -d Open a shell in the container with docker exec -it oe bash - it should have several tools pre-installed "}]