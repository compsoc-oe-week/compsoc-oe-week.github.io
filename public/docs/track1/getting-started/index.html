<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->

<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Overview#
For Track 1, we&rsquo;ve allocated 2 shared vLLM instances to be used for your solutions in the challenge. These instances are OpenAI API compatible, meaning they can be interacted with tooling and libraries originally created for working with OpenAI.
The first instance can be located at eidf219-main.vms.os.eidf.epcc.ed.ac.uk:8000 and is a Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8 model under the hood, to be used for general purpose queries and code generation. The second instance is a visual reasoning focused model and can be found at eidf219-main.vms.os.eidf.epcc.ed.ac.uk:8001 (a Qwen/Qwen2.5-VL-32B-Instruct model under the hood).">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="http://localhost:1313/docs/track1/getting-started/">
  <meta property="og:site_name" content="OE Challenge Docs">
  <meta property="og:title" content="Getting Started with Track 1">
  <meta property="og:description" content="Overview# For Track 1, weâ€™ve allocated 2 shared vLLM instances to be used for your solutions in the challenge. These instances are OpenAI API compatible, meaning they can be interacted with tooling and libraries originally created for working with OpenAI.
The first instance can be located at eidf219-main.vms.os.eidf.epcc.ed.ac.uk:8000 and is a Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8 model under the hood, to be used for general purpose queries and code generation. The second instance is a visual reasoning focused model and can be found at eidf219-main.vms.os.eidf.epcc.ed.ac.uk:8001 (a Qwen/Qwen2.5-VL-32B-Instruct model under the hood).">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="docs">
<title>Getting Started with Track 1 | OE Challenge Docs</title>
<link rel="icon" href="/favicon.png" >
<link rel="manifest" href="/manifest.json">
<link rel="canonical" href="http://localhost:1313/docs/track1/getting-started/">
<link rel="stylesheet" href="/book.min.e58fd22972c82259ceb9ea239282807a365c15b0743c7b17923e78badabbe59f.css" integrity="sha256-5Y/SKXLIIlnOueojkoKAejZcFbB0PHsXkj54utq75Z8=" crossorigin="anonymous">


  <script defer src="/fuse.min.js"></script>
  <script defer src="/en.search.min.ac248f05ad865dee53916c58e867712ce06653499cae30f90d71321516300ef1.js" integrity="sha256-rCSPBa2GXe5TkWxY6GdxLOBmU0mcrjD5DXEyFRYwDvE=" crossorigin="anonymous"></script>

  
</head>
<body dir="ltr" class="book-kind-page book-type-docs">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    
<aside class="book-menu">
  <div class="book-menu-content">
    
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>OE Challenge Docs</span>
  </a>
</h2>


<div class="book-search hidden">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>














  
  <ul>
    
      
        <li>
          
  
  

  
    <a>
      General</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/general/openeuler_container/" class="">
      START HERE - Getting started as a participant</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/general/github_repo_setup/" class="">
      Setting up your GitHub Repo</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a>
      Track 1</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/track1/getting-started/" class="active">
      Getting Started with Track 1</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a>
      Track 2</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/track2/getting-started/" class="">
      Getting Started with Track 2</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>













</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>



  </div>
</aside>
 

    <div class="book-page">
      <header class="book-header hidden">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/icons/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>Getting Started with Track 1</h3>

  <label for="toc-control">
    
    <img src="/icons/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#connecting-from-your-teams-vm">Connecting from your team&rsquo;s VM</a></li>
    <li><a href="#connecting-from-your-local-machine-with-ssh-tunelling">Connecting from your local machine with SSH tunelling</a></li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><h1 id="overview">Overview<a class="anchor" href="#overview">#</a></h1>
<p>For Track 1, we&rsquo;ve allocated 2 shared vLLM instances to be used for your solutions in the challenge. These instances are OpenAI API compatible, meaning they can be interacted with tooling and libraries originally created for working with OpenAI.</p>
<p>The first instance can be located at <code>eidf219-main.vms.os.eidf.epcc.ed.ac.uk:8000</code> and is a <code>Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8</code> model under the hood, to be used for general purpose queries and code generation. The second instance is a visual reasoning focused model and can be found at <code>eidf219-main.vms.os.eidf.epcc.ed.ac.uk:8001</code> (a <code>Qwen/Qwen2.5-VL-32B-Instruct</code> model under the hood).</p>
<h1 id="step-1-connecting-to-the-api">Step 1: Connecting to the API<a class="anchor" href="#step-1-connecting-to-the-api">#</a></h1>
<h2 id="connecting-from-your-teams-vm">Connecting from your team&rsquo;s VM<a class="anchor" href="#connecting-from-your-teams-vm">#</a></h2>
<p>The first and easiest way to connect to the API is to connect to your team&rsquo;s VM by following the instructions found <a href="">here</a>. From there, you can run a test query against the vLLM instances like so:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl http://eidf219-main.vms.os.eidf.epcc.ed.ac.uk:8000/v1/chat/completions -H <span style="color:#e6db74">&#34;Content-Type: application/json&#34;</span> -d <span style="color:#e6db74">&#39;{
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  &#34;model&#34;: &#34;Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  &#34;messages&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Give me a short introduction to large language models.&#34;}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  ],
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  &#34;temperature&#34;: 0.6,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  &#34;top_p&#34;: 0.95,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  &#34;top_k&#34;: 20,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  &#34;max_tokens&#34;: 32768
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">}&#39;</span></span></span></code></pre></div><h2 id="connecting-from-your-local-machine-with-ssh-tunelling">Connecting from your local machine with SSH tunelling<a class="anchor" href="#connecting-from-your-local-machine-with-ssh-tunelling">#</a></h2>
<p>To connect to the vLLM instances from your local machine, you can use SSH tunneling. In a standard bash shell, the command looks like so,</p>
<pre tabindex="0"><code>ssh -J &lt;your_username&gt;@eidf-gateway.epcc.ed.ac.uk -L 8000:10.1.0.155:8000 -N &lt;your_username&gt;@&lt;vm_ip&gt;</code></pre><p>where <code>&lt;your_username&gt;</code> is replaced with the username given for your team&rsquo;s VM, and <code>&lt;vm_ip&gt;</code> is the EIDF IP address associated with your team&rsquo;s VM. Note: when connecting to the visual reasoning vLLM instance (the one using a <code>Qwen/Qwen2.5-VL-32B-Instruct</code> mode), replace <code>8000:10.1.0.155:8000</code> with <code>8001:10.1.0.155:8001</code>.</p>
<p>Once you&rsquo;ve done this, in a new window you should be able to run a similar test, now by querying the API as <code>localhost:8000</code> (or <code>localhost:8001</code> if you&rsquo;re querying the visual reasoning instance).</p>
<pre tabindex="0"><code>curl http://localhost:8000/v1/chat/completions -H &#34;Content-Type: application/json&#34; -d &#39;{
  &#34;model&#34;: &#34;Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8&#34;,
  &#34;messages&#34;: [
    {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Give me a short introduction to large language models.&#34;}
  ],
  &#34;temperature&#34;: 0.6,
  &#34;top_p&#34;: 0.95,
  &#34;top_k&#34;: 20,
  &#34;max_tokens&#34;: 32768
}&#39;</code></pre><h1 id="step-2-programmatically-interacting-with-the-api">Step 2: Programmatically interacting with the API<a class="anchor" href="#step-2-programmatically-interacting-with-the-api">#</a></h1>
<p>In Python, the <code>openai</code> package can be used to interact with the vLLM instance. Under the hood, this is largely a wrapper around the OpenAI REST API, so the insights from the previous sections still apply. I&rsquo;ve included a few code samples to get you started with these below.</p>
<p>To query the <code>Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8</code> model using the <code>openai</code> package:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> openai <span style="color:#f92672">import</span> OpenAI
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>openai_api_key <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;EMPTY&#34;</span> <span style="color:#75715e"># This can be left alone</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Uncomment depending on where you&#39;re running this script:</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># openai_api_base = &#34;http://localhost:8000/v1&#34; # I&#39;m running from my local machine with SSH tunneling</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># openai_api_base = &#34;http://eidf219-main.vms.os.eidf.epcc.ed.ac.uk:8000/v1&#34; # I&#39;m running from my team&#39;s VM</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>client <span style="color:#f92672">=</span> OpenAI(
</span></span><span style="display:flex;"><span>    api_key<span style="color:#f92672">=</span>openai_api_key,
</span></span><span style="display:flex;"><span>    base_url<span style="color:#f92672">=</span>openai_api_base,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>chat_response <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>chat<span style="color:#f92672">.</span>completions<span style="color:#f92672">.</span>create(
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8&#34;</span>,
</span></span><span style="display:flex;"><span>    messages<span style="color:#f92672">=</span>[
</span></span><span style="display:flex;"><span>        {<span style="color:#e6db74">&#34;role&#34;</span>: <span style="color:#e6db74">&#34;user&#34;</span>, <span style="color:#e6db74">&#34;content&#34;</span>: <span style="color:#e6db74">&#34;Give me a short introduction to large language models.&#34;</span>},
</span></span><span style="display:flex;"><span>    ],
</span></span><span style="display:flex;"><span>    max_tokens<span style="color:#f92672">=</span><span style="color:#ae81ff">32768</span>,
</span></span><span style="display:flex;"><span>    temperature<span style="color:#f92672">=</span><span style="color:#ae81ff">0.6</span>,
</span></span><span style="display:flex;"><span>    top_p<span style="color:#f92672">=</span><span style="color:#ae81ff">0.95</span>,
</span></span><span style="display:flex;"><span>    extra_body<span style="color:#f92672">=</span>{
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;top_k&#34;</span>: <span style="color:#ae81ff">20</span>,
</span></span><span style="display:flex;"><span>    },
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Chat response:&#34;</span>, chat_response)</span></span></code></pre></div><p>To query the <code>Qwen/Qwen2.5-VL-32B-Instruct</code> model using REST API requests:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> requests
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> base64
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Uncomment depending on where you&#39;re running this script:</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># openai_api_base = &#34;http://localhost:8001/v1&#34; # I&#39;m running from my local machine with SSH tunneling</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># openai_api_base = &#34;http://eidf219-main.vms.os.eidf.epcc.ed.ac.uk:8001/v1&#34; # I&#39;m running from my team&#39;s VM</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Replace this with your actual image URL</span>
</span></span><span style="display:flex;"><span>image_url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;https://dashscope.oss-cn-beijing.aliyuncs.com/images/dog_and_girl.jpeg&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Download the image and encode it as base64</span>
</span></span><span style="display:flex;"><span>image_data <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>get(image_url)<span style="color:#f92672">.</span>content
</span></span><span style="display:flex;"><span>image_base64 <span style="color:#f92672">=</span> base64<span style="color:#f92672">.</span>b64encode(image_data)<span style="color:#f92672">.</span>decode(<span style="color:#e6db74">&#39;utf-8&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Prepare the payload for the OpenAI-compatible API</span>
</span></span><span style="display:flex;"><span>payload <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;model&#34;</span>: <span style="color:#e6db74">&#34;Qwen/Qwen2.5-VL-32B-Instruct&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;messages&#34;</span>: [
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;role&#34;</span>: <span style="color:#e6db74">&#34;user&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;content&#34;</span>: [
</span></span><span style="display:flex;"><span>                {<span style="color:#e6db74">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;image_url&#34;</span>, <span style="color:#e6db74">&#34;image_url&#34;</span>: {<span style="color:#e6db74">&#34;url&#34;</span>: <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;data:image/jpeg;base64,</span><span style="color:#e6db74">{</span>image_base64<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>}},
</span></span><span style="display:flex;"><span>                {<span style="color:#e6db74">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;text&#34;</span>, <span style="color:#e6db74">&#34;text&#34;</span>: <span style="color:#e6db74">&#34;What is inside this image?&#34;</span>}
</span></span><span style="display:flex;"><span>            ]
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Send the request to the local server</span>
</span></span><span style="display:flex;"><span>response <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>post(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>openai_api_base<span style="color:#e6db74">}</span><span style="color:#e6db74">/chat/completions&#34;</span>, json<span style="color:#f92672">=</span>payload)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print the model&#39;s response</span>
</span></span><span style="display:flex;"><span>print(response<span style="color:#f92672">.</span>json())</span></span></code></pre></div></article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">

<div>

</div>

<div>

</div>

</div>





  
  
  
  <div class="flex flex-wrap justify-between">
    <span>
    
      <a href="/docs/general/github_repo_setup/" class="flex align-center">
        <img src="/icons/backward.svg" class="book-icon" alt="Previous" title="Setting up your GitHub Repo" />
        <span>Setting up your GitHub Repo</span>
      </a>
    
    </span>
    <span>
    
      <a href="/docs/track2/getting-started/" class="flex align-center">
        <span>Getting Started with Track 2</span>
        <img src="/icons/forward.svg" class="book-icon" alt="Next" title="Getting Started with Track 2" />
      </a>
    
    </span>
  </div>
  




  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
  
  <div class="book-comments">

</div>
  
 
        
        

 
      </footer>

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    

<aside class="book-toc">
  <div class="book-toc-content">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#connecting-from-your-teams-vm">Connecting from your team&rsquo;s VM</a></li>
    <li><a href="#connecting-from-your-local-machine-with-ssh-tunelling">Connecting from your local machine with SSH tunelling</a></li>
  </ul>
</nav>



  </div>
</aside>

 
  </main>

  
</body>
</html>


















